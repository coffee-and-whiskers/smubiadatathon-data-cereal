
import logging
import json
import os
import re
from openai import OpenAI
from dotenv import load_dotenv

load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

# ========================================================================================
# JSON TO NETWORK GRAPH CONVERSION
# ========================================================================================

NETWORKVIZ_FOLDER = "networkviz"
os.makedirs(NETWORKVIZ_FOLDER, exist_ok=True) 

prompt = """
        You are an expert in data extraction, investigative analysis, and network visualization. Your task is to extract key entities, relationships, allegations, and violations from an investigation report JSON and structure them into a network graph format suitable for visualization.
        You are outlining a network graph that will allow users to understand quickly and comprehensively the report details.
        ---

        ### **Objective:**
        Given an **investigation report in JSON format**, analyze the data and extract:
        1. **Key entities** (organizations, individuals, companies, laws, and investigations). 
        2. **Relationships** (connections between entities such as audits, procurement involvement, violations, etc.).
        3. **Allegations & violations** (flag entities that are accused of or have committed regulatory breaches).
        4. **Chronological order** (assign event numbers to relationships to indicate the flow of events).
        5. If there are any entities without any edges, add in a rough description of their role or function in the investigation or report for when mouse over.
        ONLY RETURN THE JSON 
        ---

        ### **Schema Format for Output**
        **Return ONLY THE data in the following structured JSON format:**
        ```json
        {
            "entities": [
                {
                    "id": "Unique Entity Identifier",
                    "label": "Readable Entity Name",
                    "type": "organization | company | individual | statutory | investigation",
                    "outline": "allegation | violation (optional, only if applicable)"
                }
            ],
            "edges": [
                {
                    "source": "Entity ID",
                    "target": "Entity ID",
                    "label": "1. Relationship Description",
                    "tooltip": "Detailed explanation of the connection"
                }
            ],
            "allegations": {
                "Entity ID": ["List of allegations against this entity"]
            },
            "violations": {
                "Entity ID": ["List of confirmed violations for this entity"]
            }
        }

        Rough Example, be more detailed if you can:
        {
            "entities": [
                {"id": "Case 0280/04", "label": "Case 0280/04 - Tender Irregularities", "type": "investigation"},
                {"id": "UNMIK", "label": "United Nations Mission in Kosovo (UNMIK)", "type": "organization"},
                {"id": "Pristina International Airport", "label": "Pristina International Airport", "type": "organization"},
                {"id": "Chartered Accountants", "label": "Chartered Accountants (Audit)", "type": "organization"},
                
                # Allegations (Orange border - Individuals)
                {"id": "DOTI Official 1", "label": "DOTI Official (Left UNMIK 2002-06-30)", "type": "individual", "outline": "allegation"},
                
                # Companies (Green for procurement-related entities)
                {"id": "Tender Process", "label": "Tender Process for Cleaning Machines", "type": "company", "outline": "allegation"},
                
                # Statutory Violations (Purple for regulatory breaches)
                {"id": "Finance Admin Instruction 1999/2", "label": "Finance Admin Instruction 1999/2", "type": "statutory", "outline": "violation"}
            ],
            "edges": [
                {"source": "Pristina International Airport", "target": "Chartered Accountants", 
                "label": "1. Audit Conducted", "tooltip": "Financial audit was conducted at Pristina International Airport to review procurement processes."},

                {"source": "Chartered Accountants", "target": "Case 0280/04", 
                "label": "2. Audit Triggered Investigation", "tooltip": "The audit found irregularities, leading to an official investigation (Case 0280/04)."},

                {"source": "Case 0280/04", "target": "UNMIK", 
                "label": "3. Investigation Conducted By", "tooltip": "UNMIK initiated the formal investigation based on audit findings."},

                {"source": "UNMIK", "target": "Pristina International Airport", 
                "label": "4. Oversight Authority", "tooltip": "UNMIK was responsible for overseeing compliance at Pristina International Airport."},

                {"source": "Pristina International Airport", "target": "Tender Process", 
                "label": "5. Procurement Involved", "tooltip": "The airport managed the tendering process for cleaning machines, which raised concerns about favoritism."},

                {"source": "Tender Process", "target": "DOTI Official 1", 
                "label": "6. Irregularities Identified", "tooltip": "DOTI Official 1 was linked to irregularities in the tender process, including bid manipulation."},

                {"source": "Case 0280/04", "target": "Finance Admin Instruction 1999/2", 
                "label": "7. Violation Found", "tooltip": "The investigation concluded that the procurement process violated Finance Admin Instruction 1999/2."}
            ],
            "allegations": {
                "DOTI Official 1": [
                    "Potential involvement in irregularities during procurement.",
                    "Resigned from UNMIK before the investigation concluded."
                ],
                "Tender Process": [
                    "The first tender was canceled due to non-specific machine cabin descriptions.",
                    "Second tender specifications copied from a supplierâ€™s brochure, giving unfair advantage."
                ]
            },
            "violations": {
                "Finance Admin Instruction 1999/2": [
                    "Technical specifications should be drawn up with a view to fair competition and not unduly favor any particular supplier."
                ]
            }
        }
        """

def call_openai_for_graph(report_json):
    """
    Calls OpenAI GPT-4o-mini to process a JSON report and extract structured network graph data.
    """
    try:
        response = client.chat.completions.create(
            model="gpt-4o",
            messages=[
                {"role": "system", "content": "You are an expert in investigative data extraction."},
                {"role": "user", "content": prompt},
                {"role": "user", "content": json.dumps(report_json, indent=2)}
            ],
            response_format={ "type": "json_object" },
            temperature=0.3
        )

        
        response_content = response.choices[0].message.content
        logging.info("Received response from OpenAI.")
        logging.debug(f"OpenAI Raw Response:\n{response_content}")
        return json.loads(response_content)

    except Exception as e:
        logging.error(f"Error processing document with OpenAI: {e}")
        return None

def process_and_save_jsons():
    """
    Fetches JSON reports from Supabase, processes them via OpenAI to extract network graphs,
    and saves the results locally in 'networkviz' folder.
    """
    logging.info("Fetching JSON reports from Supabase...")
    try:
        response = supabase.table("ssot_reports1").select("document_name, report_data").execute()
        documents = response.data if response.data else []
    except Exception as e:
        logging.error(f"Failed to retrieve documents: {e}")
        return

    for doc in documents:
        doc_name = doc["document_name"].replace(".json", "")  # Remove .json for document ID consistency
        output_file = os.path.join(NETWORKVIZ_FOLDER, f"networkviz_{doc_name}.json")  # Define output path

        try:
            report_data = json.loads(doc["report_data"])  # Convert stored JSON string into a Python dict

            # Call OpenAI API to process the report
            graph_data = call_openai_for_graph(report_data)

            if not graph_data:
                logging.warning(f"Skipping {doc_name} due to OpenAI processing failure.")
                continue

            # Save the extracted network graph data locally
            with open(output_file, "w", encoding="utf-8") as f:
                json.dump(graph_data, f, indent=4)

            logging.info(f"Successfully saved {output_file} with extracted graph data.")

        except Exception as e:
            logging.error(f"Error processing document {doc_name}: {e}")

if __name__ == "__main__":
    logging.basicConfig(level=logging.INFO)
    process_and_save_jsons()

